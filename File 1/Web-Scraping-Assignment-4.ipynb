{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f43e0f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\hi\\appdata\\roaming\\python\\python311\\site-packages (4.12.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\hi\\appdata\\roaming\\python\\python311\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\hi\\appdata\\roaming\\python\\python311\\site-packages (from selenium) (0.10.4)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\hi\\appdata\\roaming\\python\\python311\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\hi\\appdata\\roaming\\python\\python311\\site-packages (from trio-websocket~=0.9->selenium) (1.1.3)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\hi\\appdata\\roaming\\python\\python311\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\hi\\appdata\\roaming\\python\\python311\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7aecb5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, ElementClickInterceptedException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d81c09",
   "metadata": {},
   "source": [
    "Q1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac5b19f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d29f8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank =[]\n",
    "Name =[]\n",
    "Artist =[]\n",
    "Upload_date=[]\n",
    "Views=[]\n",
    "\n",
    "try:\n",
    "    rank=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]')\n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Rank.append('NA')\n",
    "    \n",
    "try:\n",
    "    name=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]')\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Name.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Name.append('NA')\n",
    "    \n",
    "try:\n",
    "    artist=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[3]')\n",
    "    for i in artist:\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Artist.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Artist.append('NA')\n",
    "\n",
    "try:\n",
    "    upload_date=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]')\n",
    "    for i in upload_date:\n",
    "        Upload_date.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Upload_date.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Upload_date.append('NA') \n",
    "\n",
    "try:\n",
    "    views=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[4]')\n",
    "    for i in views:\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Views.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Views.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f03b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMost Viewed Video on YouTube from Wikipedia :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Uploader</th>\n",
       "      <th>Views (in Billons)</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>13.48</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.28</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>6.82</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.45</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.11</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>6.05</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>5.62</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>5.52</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.05</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.99</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>4.92</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.56</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>4.46</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.09</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.95</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.89</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Roar\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.89</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[42]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>3.80</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[43]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.75</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Sorry\"[44]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.72</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[45]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.71</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.67</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Dark Horse\"[47]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.60</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.58</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.56</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.53</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Faded\"[51]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.53</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Girls Like You\"[52]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"[53]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>3.48</td>\n",
       "      <td>May 10, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>3.48</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                       Video Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[6]   \n",
       "1    2.                                   \"Despacito\"[9]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[17]   \n",
       "3    4.                                  \"Bath Song\"[18]   \n",
       "4    5.                               \"Shape of You\"[19]   \n",
       "5    6.                              \"See You Again\"[22]   \n",
       "6    7.                          \"Wheels on the Bus\"[27]   \n",
       "7    8.                \"Phonics Song with Two Words\"[28]   \n",
       "8    9.                                \"Uptown Funk\"[29]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[30]   \n",
       "10  11.                              \"Gangnam Style\"[31]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
       "12  13.                             \"Dame Tu Cosita\"[37]   \n",
       "13  14.                                     \"Axel F\"[38]   \n",
       "14  15.                                      \"Sugar\"[39]   \n",
       "15  16.                             \"Counting Stars\"[40]   \n",
       "16  17.                                       \"Roar\"[41]   \n",
       "17  18.                        \"Baa Baa Black Sheep\"[42]   \n",
       "18  19.           \"Waka Waka (This Time for Africa)\"[43]   \n",
       "19  20.                                      \"Sorry\"[44]   \n",
       "20  21.                             \"Lakdi Ki Kathi\"[45]   \n",
       "21  22.                          \"Thinking Out Loud\"[46]   \n",
       "22  23.                                 \"Dark Horse\"[47]   \n",
       "23  24.          \"Humpty the train on a fruits ride\"[48]   \n",
       "24  25.                                    \"Perfect\"[49]   \n",
       "25  26.                                 \"Let Her Go\"[50]   \n",
       "26  27.                                      \"Faded\"[51]   \n",
       "27  28.                             \"Girls Like You\"[52]   \n",
       "28  29.                      \"Shree Hanuman Chalisa\"[53]   \n",
       "29  30.                                    \"Lean On\"[54]   \n",
       "\n",
       "                                             Uploader Views (in Billons)  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories              13.48   \n",
       "1                                          Luis Fonsi               8.28   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs               6.82   \n",
       "3                          Cocomelon - Nursery Rhymes               6.45   \n",
       "4                                          Ed Sheeran               6.11   \n",
       "5                                         Wiz Khalifa               6.05   \n",
       "6                          Cocomelon - Nursery Rhymes               5.62   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs               5.52   \n",
       "8                                         Mark Ronson               5.05   \n",
       "9                                         Miroshka TV               4.99   \n",
       "10                                        officialpsy               4.92   \n",
       "11                                         Get Movies               4.56   \n",
       "12                                      Ultra Records               4.46   \n",
       "13                                         Crazy Frog               4.09   \n",
       "14                                           Maroon 5               3.95   \n",
       "15                                        OneRepublic               3.89   \n",
       "16                                         Katy Perry               3.89   \n",
       "17                         Cocomelon - Nursery Rhymes               3.80   \n",
       "18                                            Shakira               3.75   \n",
       "19                                      Justin Bieber               3.72   \n",
       "20                                       Jingle Toons               3.71   \n",
       "21                                         Ed Sheeran               3.67   \n",
       "22                                         Katy Perry               3.60   \n",
       "23      Kiddiestv Hindi - Nursery Rhymes & Kids Songs               3.58   \n",
       "24                                         Ed Sheeran               3.56   \n",
       "25                                          Passenger               3.53   \n",
       "26                                        Alan Walker               3.53   \n",
       "27                                           Maroon 5               3.50   \n",
       "28                              T-Series Bhakti Sagar               3.48   \n",
       "29                               Major Lazer Official               3.48   \n",
       "\n",
       "          Upload Date  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3         May 2, 2018  \n",
       "4    January 30, 2017  \n",
       "5       April 6, 2015  \n",
       "6        May 24, 2018  \n",
       "7       March 6, 2014  \n",
       "8   November 19, 2014  \n",
       "9   February 27, 2018  \n",
       "10      July 15, 2012  \n",
       "11   January 31, 2012  \n",
       "12      April 5, 2018  \n",
       "13      June 16, 2009  \n",
       "14   January 14, 2015  \n",
       "15       May 31, 2013  \n",
       "16  September 5, 2013  \n",
       "17      June 25, 2018  \n",
       "18       June 4, 2010  \n",
       "19   October 22, 2015  \n",
       "20      June 14, 2018  \n",
       "21    October 7, 2014  \n",
       "22  February 20, 2014  \n",
       "23   January 26, 2018  \n",
       "24   November 9, 2017  \n",
       "25      July 25, 2012  \n",
       "26   December 3, 2015  \n",
       "27       May 31, 2018  \n",
       "28       May 10, 2011  \n",
       "29     March 22, 2015  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rank':Rank,'Video Name':Name,'Uploader':Artist,'Views (in Billons)':Views,'Upload Date':Upload_date})\n",
    "print('\\033[1m'+'Most Viewed Video on YouTube from Wikipedia :'+'\\033[0m')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017af550",
   "metadata": {},
   "source": [
    "Q2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70e6d883",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f34356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//button[@class=\"close-button page-close\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e032060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "international=driver.find_element(By.XPATH,'/html/body/div[3]/ul/li/a[2]')\n",
    "try:\n",
    "    international.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(fixtures.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0de2b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title = []\n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time = []\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    title=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "    for i in title:\n",
    "        Title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Title.append('NA')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    series=driver.find_elements(By.XPATH,'//span[@class=\"teamTypeTag ng-scope\"]')\n",
    "    for i in series:\n",
    "        Series.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Series.append('NA')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    place=driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]')\n",
    "    for i in place:\n",
    "        Place.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Place.append('NA')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    date=driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "    for i in date:\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append('NA')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    time=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "    for i in time:\n",
    "        Time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Time.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3c5f5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Men</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "      <td>19 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Men</td>\n",
       "      <td>Narendra Modi Stadium, Ahmedabad</td>\n",
       "      <td>14 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Men</td>\n",
       "      <td>Arun Jaitley Stadium, Delhi</td>\n",
       "      <td>11 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Men</td>\n",
       "      <td>MA Chidambaram Stadium, Chennai</td>\n",
       "      <td>8 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19TH ASIAN GAMES HANGZHOU 2022</td>\n",
       "      <td>Men</td>\n",
       "      <td>Pingfeng Cricket Field, Hangzhou</td>\n",
       "      <td>7 OCTOBER, 2023</td>\n",
       "      <td>11:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19TH ASIAN GAMES HANGZHOU 2022</td>\n",
       "      <td>Men</td>\n",
       "      <td>Pingfeng Cricket Field, Hangzhou</td>\n",
       "      <td>6 OCTOBER, 2023</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ICC MENS WORLD CUP 2023 WARM-UP MATCHES</td>\n",
       "      <td>Men</td>\n",
       "      <td>Greenfield International Stadium, Thiruvananth...</td>\n",
       "      <td>3 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19TH ASIAN GAMES HANGZHOU 2022</td>\n",
       "      <td>Men</td>\n",
       "      <td>Pingfeng Cricket Field, Hangzhou</td>\n",
       "      <td>3 OCTOBER, 2023</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ICC MENS WORLD CUP 2023 WARM-UP MATCHES</td>\n",
       "      <td>Men</td>\n",
       "      <td>Barsapara Cricket Stadium, Guwahati</td>\n",
       "      <td>30 SEPTEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Match Title Tournament  \\\n",
       "0                  ICC MENS WORLD CUP 2023        Men   \n",
       "1                  ICC MENS WORLD CUP 2023        Men   \n",
       "2                  ICC MENS WORLD CUP 2023        Men   \n",
       "3                  ICC MENS WORLD CUP 2023        Men   \n",
       "4           19TH ASIAN GAMES HANGZHOU 2022        Men   \n",
       "5           19TH ASIAN GAMES HANGZHOU 2022        Men   \n",
       "6  ICC MENS WORLD CUP 2023 WARM-UP MATCHES        Men   \n",
       "7           19TH ASIAN GAMES HANGZHOU 2022        Men   \n",
       "8  ICC MENS WORLD CUP 2023 WARM-UP MATCHES        Men   \n",
       "\n",
       "                                               Venue                Date  \\\n",
       "0      Maharashtra Cricket Association Stadium, Pune    19 OCTOBER, 2023   \n",
       "1                   Narendra Modi Stadium, Ahmedabad    14 OCTOBER, 2023   \n",
       "2                        Arun Jaitley Stadium, Delhi    11 OCTOBER, 2023   \n",
       "3                    MA Chidambaram Stadium, Chennai     8 OCTOBER, 2023   \n",
       "4                   Pingfeng Cricket Field, Hangzhou     7 OCTOBER, 2023   \n",
       "5                   Pingfeng Cricket Field, Hangzhou     6 OCTOBER, 2023   \n",
       "6  Greenfield International Stadium, Thiruvananth...     3 OCTOBER, 2023   \n",
       "7                   Pingfeng Cricket Field, Hangzhou     3 OCTOBER, 2023   \n",
       "8                Barsapara Cricket Stadium, Guwahati  30 SEPTEMBER, 2023   \n",
       "\n",
       "           Time  \n",
       "0   2:00 PM IST  \n",
       "1   2:00 PM IST  \n",
       "2   2:00 PM IST  \n",
       "3   2:00 PM IST  \n",
       "4  11:30 AM IST  \n",
       "5   6:30 AM IST  \n",
       "6   2:00 PM IST  \n",
       "7   6:30 AM IST  \n",
       "8   2:00 PM IST  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Match Title':Title,'Tournament':Series,'Venue':Place,'Date':Date,'Time':Time})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab919a3",
   "metadata": {},
   "source": [
    "Q3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3cc7f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "driver.get(\"https://www.statisticstimes.com/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6041cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"top\"]/div[2]/div[2]/button').click()\n",
    "driver.find_element(By.XPATH,'//*[@id=\"top\"]/div[2]/div[2]/div/a[3]').click()\n",
    "driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9febf1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "try:\n",
    "    ranks=driver.find_elements(By.XPATH,'//div[@id=\"table_id_wrapper\"]/table/tbody/tr/td[1]')\n",
    "    for i in ranks:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:                 \n",
    "    rank.append('NA')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "State=[]\n",
    "try:\n",
    "    states=driver.find_elements(By.XPATH,'//div[@id=\"table_id_wrapper\"]/table/tbody/tr/td[2]')\n",
    "    for i in states:\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:                 \n",
    "    State.append('NA')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "GSDP_20=[]\n",
    "try:\n",
    "    info=driver.find_elements(By.XPATH,'//div[@id=\"table_id_wrapper\"]/table/tbody/tr/td[3]')\n",
    "    for i in info:\n",
    "        GSDP_20.append(i.text)\n",
    "except NoSuchElementException:           \n",
    "    GSDP_20.append('NA')\n",
    "time.sleep(2)    \n",
    "    \n",
    "\n",
    "GSDP_19=[]\n",
    "try:\n",
    "    info=driver.find_elements(By.XPATH,'//div[@id=\"table_id_wrapper\"]/table/tbody/tr/td[4]')\n",
    "    for i in info:\n",
    "        GSDP_19.append(i.text)\n",
    "except NoSuchElementException:       \n",
    "    GSDP_19.append('NA')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "share=[]\n",
    "try:\n",
    "    info=driver.find_elements(By.XPATH,'//div[@id=\"table_id_wrapper\"]/table/tbody/tr/td[5]')\n",
    "    for i in info:\n",
    "        share.append(i.text)\n",
    "except NoSuchElementException:       \n",
    "    share.append('NA')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "GDP_billion=[]\n",
    "try:\n",
    "    info=driver.find_elements(By.XPATH,'//div[@id=\"table_id_wrapper\"]/table/tbody/tr/td[6]')\n",
    "    for i in info:\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:          \n",
    "    GDP_billion.append('NA')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35ced191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP(Billion_$)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(19-20) GSDP(18-19) Share(18-19)  \\\n",
       "0     1                Maharashtra           -   2,632,792       13.94%   \n",
       "1     2                 Tamil Nadu   1,845,853   1,630,208        8.63%   \n",
       "2     3              Uttar Pradesh   1,687,818   1,584,764        8.39%   \n",
       "3     4                    Gujarat           -   1,502,899        7.96%   \n",
       "4     5                  Karnataka   1,631,977   1,493,127        7.91%   \n",
       "5     6                West Bengal   1,253,832   1,089,898        5.77%   \n",
       "6     7                  Rajasthan   1,020,989     942,586        4.99%   \n",
       "7     8             Andhra Pradesh     972,782     862,957        4.57%   \n",
       "8     9                  Telangana     969,604     861,031        4.56%   \n",
       "9    10             Madhya Pradesh     906,672     809,592        4.29%   \n",
       "10   11                     Kerala           -     781,653        4.14%   \n",
       "11   12                      Delhi     856,112     774,870        4.10%   \n",
       "12   13                    Haryana     831,610     734,163        3.89%   \n",
       "13   14                      Bihar     611,804     530,363        2.81%   \n",
       "14   15                     Punjab     574,760     526,376        2.79%   \n",
       "15   16                     Odisha     521,275     487,805        2.58%   \n",
       "16   17                      Assam           -     315,881        1.67%   \n",
       "17   18               Chhattisgarh     329,180     304,063        1.61%   \n",
       "18   19                  Jharkhand     328,598     297,204        1.57%   \n",
       "19   20                Uttarakhand           -     245,895        1.30%   \n",
       "20   21            Jammu & Kashmir           -     155,956        0.83%   \n",
       "21   22           Himachal Pradesh     165,472     153,845        0.81%   \n",
       "22   23                        Goa      80,449      73,170        0.39%   \n",
       "23   24                    Tripura      55,984      49,845        0.26%   \n",
       "24   25                 Chandigarh           -      42,114        0.22%   \n",
       "25   26                 Puducherry      38,253      34,433        0.18%   \n",
       "26   27                  Meghalaya      36,572      33,481        0.18%   \n",
       "27   28                     Sikkim      32,496      28,723        0.15%   \n",
       "28   29                    Manipur      31,790      27,870        0.15%   \n",
       "29   30                   Nagaland           -      27,283        0.14%   \n",
       "30   31          Arunachal Pradesh           -      24,603        0.13%   \n",
       "31   32                    Mizoram      26,503      22,287        0.12%   \n",
       "32   33  Andaman & Nicobar Islands           -           -            -   \n",
       "\n",
       "   GDP(Billion_$)  \n",
       "0         399.921  \n",
       "1         247.629  \n",
       "2         240.726  \n",
       "3         228.290  \n",
       "4         226.806  \n",
       "5         165.556  \n",
       "6         143.179  \n",
       "7         131.083  \n",
       "8         130.791  \n",
       "9         122.977  \n",
       "10        118.733  \n",
       "11        117.703  \n",
       "12        111.519  \n",
       "13         80.562  \n",
       "14         79.957  \n",
       "15         74.098  \n",
       "16         47.982  \n",
       "17         46.187  \n",
       "18         45.145  \n",
       "19         37.351  \n",
       "20         23.690  \n",
       "21         23.369  \n",
       "22         11.115  \n",
       "23          7.571  \n",
       "24          6.397  \n",
       "25          5.230  \n",
       "26          5.086  \n",
       "27          4.363  \n",
       "28          4.233  \n",
       "29          4.144  \n",
       "30          3.737  \n",
       "31          3.385  \n",
       "32              -  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rank':rank,'State':State,'GSDP(19-20)':GSDP_20,'GSDP(18-19)':GSDP_19,'Share(18-19)':share,'GDP(Billion_$)':GDP_billion})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec110dbc",
   "metadata": {},
   "source": [
    "Q4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7ed70da",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "driver.get(\"https://github.com/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb214f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "explore.click()\n",
    "time.sleep(2)\n",
    "\n",
    "explore=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "try:\n",
    "    explore.click()\n",
    "except:\n",
    "    driver.get(explore.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4af1ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_urls=[]\n",
    "Contributors_count=[]\n",
    "Language_used=[]\n",
    "repo_title=[]\n",
    "repo_desc=[]\n",
    "\n",
    "#scraping repositories urls\n",
    "repos=driver.find_elements(By.XPATH,'//a[@class=\"Link\"]')\n",
    "for i in repos:\n",
    "    repo_urls.append(i.get_attribute('href'))\n",
    "time.sleep(2) \n",
    "\n",
    "    \n",
    "#scraping repositories title\n",
    "repo_title=[]\n",
    "try:\n",
    "    repos=driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]')\n",
    "    for i in repos:\n",
    "        repo_title.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    repo_title.append('No details available')\n",
    "time.sleep(3)\n",
    "    \n",
    "\n",
    "for i in repo_urls:\n",
    "    driver.get(i)\n",
    "    l=[]\n",
    "    time.sleep(3)\n",
    "    #scraping repositories discription\n",
    "    try:\n",
    "        repo = driver.find_element(By.XPATH,'//*[@id=\"repo-content-pjax-container\"]/div/div/div[2]/div[2]/div/div[1]/div/p')\n",
    "        repo_desc.append(repo.text)\n",
    "    except NoSuchElementException:\n",
    "        repo_desc.append('-')\n",
    "    \n",
    "    #scraping contributors count\n",
    "    try:\n",
    "        count=driver.find_element(By.XPATH,'//h2[@class=\"h4 mb-3\"]/a[contains(text(),\"Contributors\")]/span')\n",
    "        Contributors_count.append(count.text)\n",
    "    except NoSuchElementException:#handling no such element exception\n",
    "        Contributors_count.append('No details available')\n",
    "    time.sleep(2)\n",
    "    \n",
    "     #scraping languages used   \n",
    "    languages=driver.find_elements(By.XPATH,'//li[@class=\"d-inline\"]//a//span[1]')\n",
    "    if languages:    \n",
    "        for i in languages:\n",
    "            l.append(i.text)\n",
    "    else:\n",
    "        l.append('No languages used')\n",
    "    Language_used.append(l)   \n",
    "    \n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f3f84ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>Language_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ByteByteGoHq / system-design-101</td>\n",
       "      <td>Explain complex systems using visuals and simp...</td>\n",
       "      <td>5</td>\n",
       "      <td>[No languages used]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cpacker / MemGPT</td>\n",
       "      <td>Teaching LLMs memory management for unbounded ...</td>\n",
       "      <td>7</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JonathonLuiten / Dynamic3DGaussians</td>\n",
       "      <td>-</td>\n",
       "      <td>No details available</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>omnivore-app / omnivore</td>\n",
       "      <td>Omnivore is a complete, open source read-it-la...</td>\n",
       "      <td>33</td>\n",
       "      <td>[HTML, TypeScript, Swift, JavaScript, Kotlin, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spdustin / ChatGPT-AutoExpert</td>\n",
       "      <td>🚀🧠💬 Supercharged Custom Instructions for ChatG...</td>\n",
       "      <td>3</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>geekan / MetaGPT</td>\n",
       "      <td>🌟 The Multi-Agent Framework: Given one line Re...</td>\n",
       "      <td>35</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cloudcommunity / Free-Certifications</td>\n",
       "      <td>A curated list of free courses &amp; certifications.</td>\n",
       "      <td>48</td>\n",
       "      <td>[No languages used]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>yanfengwu-syser / syserdebugger</td>\n",
       "      <td>-</td>\n",
       "      <td>No details available</td>\n",
       "      <td>[C++, C, Batchfile, HTML, Assembly, XSLT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>barnamenevisi / free-resources</td>\n",
       "      <td>، تمام منابع آموزشی معرفی شده رایگان هستن برای...</td>\n",
       "      <td>4</td>\n",
       "      <td>[No languages used]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PWhiddy / PokemonRedExperiments</td>\n",
       "      <td>Playing Pokemon Red with Reinforcement Learning</td>\n",
       "      <td>4</td>\n",
       "      <td>[Jupyter Notebook, Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Orange-Cyberdefense / GOAD</td>\n",
       "      <td>game of active directory</td>\n",
       "      <td>15</td>\n",
       "      <td>[PowerShell, Shell, HCL, Jinja, ASP.NET, Docke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TheRealJoelmatic / RemoveAdblockThing</td>\n",
       "      <td>Removes The \"Ad blocker are not allowed on You...</td>\n",
       "      <td>4</td>\n",
       "      <td>[JavaScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>awesome-selfhosted / awesome-selfhosted</td>\n",
       "      <td>A list of Free Software network services and w...</td>\n",
       "      <td>1,262</td>\n",
       "      <td>[No languages used]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>oceanbase / miniob</td>\n",
       "      <td>MiniOB is a compact database that assists deve...</td>\n",
       "      <td>25</td>\n",
       "      <td>[C++, Python, C, Yacc, Lua, CMake]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cockpit-project / cockpit</td>\n",
       "      <td>Cockpit is a web-based graphical interface for...</td>\n",
       "      <td>187</td>\n",
       "      <td>[C, JavaScript, Python, SCSS, Shell, HTML]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>localsend / localsend</td>\n",
       "      <td>An open source cross-platform alternative to A...</td>\n",
       "      <td>64</td>\n",
       "      <td>[Dart, C++, CMake, Swift, PowerShell, HTML]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>refinedev / refine</td>\n",
       "      <td>Build your React-based CRUD applications, with...</td>\n",
       "      <td>179</td>\n",
       "      <td>[TypeScript, JavaScript, CSS, HTML, Handlebars...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>uutils / coreutils</td>\n",
       "      <td>Cross-platform Rust rewrite of the GNU coreutils</td>\n",
       "      <td>428</td>\n",
       "      <td>[Rust, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pi-hole / pi-hole</td>\n",
       "      <td>A black hole for Internet advertisements</td>\n",
       "      <td>220</td>\n",
       "      <td>[Shell, Python, Roff, Dockerfile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hustvl / 4DGaussians</td>\n",
       "      <td>4D Gaussian Splatting for Real-Time Dynamic Sc...</td>\n",
       "      <td>4</td>\n",
       "      <td>[Jupyter Notebook, Python, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>huggingface / text-embeddings-inference</td>\n",
       "      <td>A blazing fast inference solution for text emb...</td>\n",
       "      <td>No details available</td>\n",
       "      <td>[Rust, Python, JavaScript, Dockerfile, Makefile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TeamPiped / Piped</td>\n",
       "      <td>An alternative privacy-friendly YouTube fronte...</td>\n",
       "      <td>184</td>\n",
       "      <td>[Vue, JavaScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>wagtail / wagtail</td>\n",
       "      <td>A Django content management system focused on ...</td>\n",
       "      <td>690</td>\n",
       "      <td>[Python, JavaScript, HTML, TypeScript, SCSS, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TheAlgorithms / Python</td>\n",
       "      <td>All Algorithms implemented in Python</td>\n",
       "      <td>1,093</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Vision-CAIR / MiniGPT-4</td>\n",
       "      <td>Open-sourced codes for MiniGPT-4 and MiniGPT-v2</td>\n",
       "      <td>11</td>\n",
       "      <td>[Python, Shell]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title  \\\n",
       "0          ByteByteGoHq / system-design-101   \n",
       "1                          cpacker / MemGPT   \n",
       "2       JonathonLuiten / Dynamic3DGaussians   \n",
       "3                   omnivore-app / omnivore   \n",
       "4             spdustin / ChatGPT-AutoExpert   \n",
       "5                          geekan / MetaGPT   \n",
       "6      cloudcommunity / Free-Certifications   \n",
       "7           yanfengwu-syser / syserdebugger   \n",
       "8            barnamenevisi / free-resources   \n",
       "9           PWhiddy / PokemonRedExperiments   \n",
       "10               Orange-Cyberdefense / GOAD   \n",
       "11    TheRealJoelmatic / RemoveAdblockThing   \n",
       "12  awesome-selfhosted / awesome-selfhosted   \n",
       "13                       oceanbase / miniob   \n",
       "14                cockpit-project / cockpit   \n",
       "15                    localsend / localsend   \n",
       "16                       refinedev / refine   \n",
       "17                       uutils / coreutils   \n",
       "18                        pi-hole / pi-hole   \n",
       "19                     hustvl / 4DGaussians   \n",
       "20  huggingface / text-embeddings-inference   \n",
       "21                        TeamPiped / Piped   \n",
       "22                        wagtail / wagtail   \n",
       "23                   TheAlgorithms / Python   \n",
       "24                  Vision-CAIR / MiniGPT-4   \n",
       "\n",
       "                                          Description    Contributors_count  \\\n",
       "0   Explain complex systems using visuals and simp...                     5   \n",
       "1   Teaching LLMs memory management for unbounded ...                     7   \n",
       "2                                                   -  No details available   \n",
       "3   Omnivore is a complete, open source read-it-la...                    33   \n",
       "4   🚀🧠💬 Supercharged Custom Instructions for ChatG...                     3   \n",
       "5   🌟 The Multi-Agent Framework: Given one line Re...                    35   \n",
       "6    A curated list of free courses & certifications.                    48   \n",
       "7                                                   -  No details available   \n",
       "8   ، تمام منابع آموزشی معرفی شده رایگان هستن برای...                     4   \n",
       "9     Playing Pokemon Red with Reinforcement Learning                     4   \n",
       "10                           game of active directory                    15   \n",
       "11  Removes The \"Ad blocker are not allowed on You...                     4   \n",
       "12  A list of Free Software network services and w...                 1,262   \n",
       "13  MiniOB is a compact database that assists deve...                    25   \n",
       "14  Cockpit is a web-based graphical interface for...                   187   \n",
       "15  An open source cross-platform alternative to A...                    64   \n",
       "16  Build your React-based CRUD applications, with...                   179   \n",
       "17   Cross-platform Rust rewrite of the GNU coreutils                   428   \n",
       "18           A black hole for Internet advertisements                   220   \n",
       "19  4D Gaussian Splatting for Real-Time Dynamic Sc...                     4   \n",
       "20  A blazing fast inference solution for text emb...  No details available   \n",
       "21  An alternative privacy-friendly YouTube fronte...                   184   \n",
       "22  A Django content management system focused on ...                   690   \n",
       "23               All Algorithms implemented in Python                 1,093   \n",
       "24    Open-sourced codes for MiniGPT-4 and MiniGPT-v2                    11   \n",
       "\n",
       "                                        Language_used  \n",
       "0                                 [No languages used]  \n",
       "1                                            [Python]  \n",
       "2                                            [Python]  \n",
       "3   [HTML, TypeScript, Swift, JavaScript, Kotlin, ...  \n",
       "4                                            [Python]  \n",
       "5                                            [Python]  \n",
       "6                                 [No languages used]  \n",
       "7           [C++, C, Batchfile, HTML, Assembly, XSLT]  \n",
       "8                                 [No languages used]  \n",
       "9                          [Jupyter Notebook, Python]  \n",
       "10  [PowerShell, Shell, HCL, Jinja, ASP.NET, Docke...  \n",
       "11                                       [JavaScript]  \n",
       "12                                [No languages used]  \n",
       "13                 [C++, Python, C, Yacc, Lua, CMake]  \n",
       "14         [C, JavaScript, Python, SCSS, Shell, HTML]  \n",
       "15        [Dart, C++, CMake, Swift, PowerShell, HTML]  \n",
       "16  [TypeScript, JavaScript, CSS, HTML, Handlebars...  \n",
       "17                                      [Rust, Shell]  \n",
       "18                  [Shell, Python, Roff, Dockerfile]  \n",
       "19                  [Jupyter Notebook, Python, Shell]  \n",
       "20   [Rust, Python, JavaScript, Dockerfile, Makefile]  \n",
       "21                                  [Vue, JavaScript]  \n",
       "22  [Python, JavaScript, HTML, TypeScript, SCSS, S...  \n",
       "23                                           [Python]  \n",
       "24                                    [Python, Shell]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Title':repo_title,'Description':repo_desc,'Contributors_count':Contributors_count,'Language_used':Language_used})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77630a3",
   "metadata": {},
   "source": [
    "Q5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b59d6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "driver.get(\"https://www.billboard.com/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b3522c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard=driver.find_element(By.XPATH,'//*[@id=\"main-wrapper\"]/header/div/div[3]/div/nav/ul/li[4]/a')\n",
    "try:\n",
    "    billboard.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(charts.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69b8dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_name=[]\n",
    "try:\n",
    "    names=driver.find_elements(By.XPATH,'//h3[@class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\"]')\n",
    "    for i in names:\n",
    "        song_name.append(i.text)\n",
    "except NoSuchElementException:       \n",
    "    song_name.append('NA')\n",
    "time.sleep(2)    \n",
    "\n",
    "\n",
    "#scraping artist_names \n",
    "artist_name=[]\n",
    "try:\n",
    "    names=driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]')\n",
    "    for i in names:\n",
    "        artist_name.append(i.text)\n",
    "except NoSuchElementException:       \n",
    "    artist_name.append('NA')\n",
    "time.sleep(2)\n",
    "    \n",
    "\n",
    "\n",
    "last_week_rank=[]\n",
    "try:\n",
    "    ranks=driver.find_elements(By.XPATH,'//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div[3]/ul/li[4]/ul/li[4]/span')\n",
    "    for i in ranks:\n",
    "        last_week_rank.append(i.text)\n",
    "except NoSuchElementException:        \n",
    "    last_week_rank.append('NA') \n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "peak_rank=[]\n",
    "try:\n",
    "    ranks=driver.find_elements(By.XPATH,'//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div[3]/ul/li[4]/ul/li[5]/span')\n",
    "    for i in ranks:\n",
    "        peak_rank.append(i.text)\n",
    "except NoSuchElementException:     \n",
    "    peak_rank.append('NA')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "weeks=[]\n",
    "try:\n",
    "    week_count=driver.find_elements(By.XPATH,'//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div[3]/ul/li[4]/ul/li[6]/span')\n",
    "    for i in week_count:\n",
    "        weeks.append(i.text)\n",
    "except NoSuchElementException:          \n",
    "    weeks.append('NA')\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9be2e1a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSong_Name\u001b[39m\u001b[38;5;124m'\u001b[39m:song_name,\n\u001b[0;32m      2\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArtist_Name\u001b[39m\u001b[38;5;124m'\u001b[39m:artist_name,\n\u001b[0;32m      3\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLast_week_rank\u001b[39m\u001b[38;5;124m'\u001b[39m:last_week_rank,\n\u001b[0;32m      4\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPeak\u001b[39m\u001b[38;5;124m'\u001b[39m:peak_rank,\n\u001b[0;32m      5\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeeks_on_chart\u001b[39m\u001b[38;5;124m'\u001b[39m:weeks})\n\u001b[0;32m      6\u001b[0m df\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame({'Song_Name':song_name,\n",
    "                'Artist_Name':artist_name,\n",
    "                'Last_week_rank':last_week_rank,\n",
    "                'Peak':peak_rank,\n",
    "                'Weeks_on_chart':weeks})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f605e8",
   "metadata": {},
   "source": [
    "Q6. Scrape the details of Highest selling novels.\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a269b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "628dd480",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name=[]\n",
    "try:\n",
    "    names=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "    for i in names:\n",
    "        book_name.append(i.text)\n",
    "except NoSuchElementException:              \n",
    "    book_name.append('NA')\n",
    "time.sleep(2)\n",
    "\n",
    "author_name=[]\n",
    "try:\n",
    "    names=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "    for i in names:\n",
    "        author_name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    author_name.append('NA')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "Sale=[]\n",
    "try:\n",
    "    sale=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "    for i in sale:\n",
    "        Sale.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Sale.append('NA')\n",
    "time.sleep(2)    \n",
    "\n",
    "publisher=[]\n",
    "try:\n",
    "    publishers=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "    for i in publishers:\n",
    "        publisher.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    publisher.append('NA')\n",
    "time.sleep(2)\n",
    "\n",
    "genre=[]\n",
    "try:\n",
    "    genres=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "    for i in genres:\n",
    "        genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    genre.append('NA')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b221612d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_name       Author_name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Book_name\":book_name,\"Author_name\":author_name,'Volume sold':Sale,'Publisher':publisher,'Genre':genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc37f9ae",
   "metadata": {},
   "source": [
    "Q7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce91745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae8ee3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "try:\n",
    "    names=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')\n",
    "    for i in names:\n",
    "        name.append(i.text)\n",
    "except NosuchElementException:\n",
    "    name.append('NA')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "years=[]\n",
    "try:\n",
    "    span=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/span[2]')\n",
    "    for i in span:\n",
    "        years.append(i.text)\n",
    "except NosuchElementException:\n",
    "    years.append('NA')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "genre=[]\n",
    "try:\n",
    "    genres=driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')\n",
    "    for i in genres:\n",
    "        genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    genre.append('NA')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "run_time=[]\n",
    "try:\n",
    "    info=driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]')\n",
    "    for i in info:\n",
    "        run_time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    run_time.append('NA')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "rating=[]\n",
    "try:\n",
    "    info=driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]/span[2]')\n",
    "    for i in info:\n",
    "        rating.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    rating.append('NA')\n",
    "time.sleep(2)\n",
    "\n",
    "votes=[]\n",
    "try:\n",
    "    info=driver.find_elements(By.XPATH,'//span[@name=\"nv\"]')\n",
    "    for i in info:\n",
    "        votes.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    votes.append('NA')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c5f9a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>years</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,213,598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,283,355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,050,445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>308,641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>267,579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>52,961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>65,033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>211,940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>44,114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>270,216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name        years                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_time Rating      Votes  \n",
       "0    57 min    9.2  2,213,598  \n",
       "1    51 min    8.7  1,283,355  \n",
       "2    44 min    8.1  1,050,445  \n",
       "3    60 min    7.5    308,641  \n",
       "4    43 min    7.6    267,579  \n",
       "..      ...    ...        ...  \n",
       "95   42 min    7.5     52,961  \n",
       "96   50 min    7.8     65,033  \n",
       "97   42 min    8.1    211,940  \n",
       "98   45 min      7     44,114  \n",
       "99  572 min    8.6    270,216  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Name\":name,\"years\":years,\"Genre\":genre,\"Run_time\":run_time,\"Rating\":rating,\"Votes\":votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332300ce",
   "metadata": {},
   "source": [
    "Q8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/ You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43938867",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "driver.get(\"https://archive.ics.uci.edu/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33e79acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "show=driver.find_element(By.XPATH,'//a[@class=\"btn-primary btn\"]')\n",
    "show.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e7015d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "try:\n",
    "    names=driver.find_elements(By.XPATH,'//h2[@class=\"truncate text-primary\"]')\n",
    "    for i in names:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    name.append('NA')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "data_type=[]\n",
    "try:\n",
    "    data=driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div[1]/div/div[2]/div/div[2]/span')\n",
    "    for i in data[1:]:\n",
    "         data_type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    data_type.append(\"NA\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "Task=[]\n",
    "try:\n",
    "    task=driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div[1]/div/div[2]/div/div[1]/span')\n",
    "    for i in task[1:]:\n",
    "        Task.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Task.append(\"NA\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "no_of_instances=[]\n",
    "try:\n",
    "    instance=driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div[1]/div/div[2]/div/div[3]/span')\n",
    "    for i in instance[1:]:\n",
    "         no_of_instances.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    no_of_instances.append(\"NA\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "no_of_attributes=[]\n",
    "try:\n",
    "    attribute=driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div[1]/div/div[2]/div/div[4]/span')\n",
    "    for i in attribute[1:]:\n",
    "         no_of_attributes.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    no_of_attributes.append(\"NA\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47804f41",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m:name,\n\u001b[0;32m      2\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData_type\u001b[39m\u001b[38;5;124m'\u001b[39m:data_type,\n\u001b[0;32m      3\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTask\u001b[39m\u001b[38;5;124m'\u001b[39m:default_task,\n\u001b[0;32m      4\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo_of_instances\u001b[39m\u001b[38;5;124m'\u001b[39m:no_of_instances,\n\u001b[0;32m      5\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo_of_attributes\u001b[39m\u001b[38;5;124m'\u001b[39m:no_of_attributes})\n\u001b[0;32m      6\u001b[0m df\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame({'Name':name,\n",
    "                'Data_type':data_type,\n",
    "                'Task':default_task,\n",
    "                'No_of_instances':no_of_instances,\n",
    "                'No_of_attributes':no_of_attributes})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e36083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
